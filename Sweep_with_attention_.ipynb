{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShahistaAfreen/DL_DA6401_A3/blob/main/Sweep_with_attention_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2vkvje2XA3r"
      },
      "source": [
        "# Import package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0qCvgqBxzLo",
        "outputId": "9d8137c9-8a41-41e4-c65b-61fffaf4c917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.28.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Collecting xtarfile\n",
            "  Downloading xtarfile-0.2.1.tar.gz (7.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: xtarfile\n",
            "  Building wheel for xtarfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xtarfile: filename=xtarfile-0.2.1-py3-none-any.whl size=8056 sha256=750e6e14450bf0cc6cf8cb792a2899abdda8477392af016b7130066039c7ce1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/de/d6/def0eebfc3d5adb3a866d1bd9ae45649e07e6cffb284314a00\n",
            "Successfully built xtarfile\n",
            "Installing collected packages: xtarfile\n",
            "Successfully installed xtarfile-0.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb\n",
        "!pip install xtarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xAqFEssB1RJ"
      },
      "outputs": [],
      "source": [
        "START_TOKEN=\"\\t\"\n",
        "END_TOKEN=\"\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6xB0KDuy95e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "import string\n",
        "import tarfile\n",
        "from os.path import exists\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Data manipulation libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualization\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "# Deep learning frameworks\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import tensorflow.keras.backend as K\n",
        "import keras\n",
        "\n",
        "# Experiment tracking\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NRptwepnCOo"
      },
      "source": [
        "# **Bahdanau Attention**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0PrBwnhvaz6"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Attention mechanism for sequence processing\n",
        "\"\"\"\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    \"\"\"Initialize attention mechanism with specified units\n",
        "\n",
        "    Args:\n",
        "        units: Dimensionality of the attention space\n",
        "    \"\"\"\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "\n",
        "    # Define trainable parameters\n",
        "    self.W1 = tf.keras.layers.Dense(units)  # Transform encoder state\n",
        "    self.W2 = tf.keras.layers.Dense(units)  # Transform encoder outputs\n",
        "    self.V = tf.keras.layers.Dense(1)       # Project to attention scores\n",
        "\n",
        "  def call(self, enc_state, enc_out):\n",
        "    \"\"\"Compute attention context vector\n",
        "\n",
        "    Args:\n",
        "        enc_state: Hidden state from encoder\n",
        "        enc_out: Output sequence from encoder\n",
        "\n",
        "    Returns:\n",
        "        Tuple of context vector and attention weights\n",
        "    \"\"\"\n",
        "    # Prepare encoder state for attention calculation\n",
        "    combined_state = tf.concat(enc_state, axis=1)\n",
        "    reshaped_state = tf.expand_dims(combined_state, axis=1)\n",
        "\n",
        "    # Compute attention energy scores\n",
        "    energy = tf.nn.tanh(self.W1(reshaped_state) + self.W2(enc_out))\n",
        "    attention_score = self.V(energy)\n",
        "\n",
        "    # Apply softmax to get probability distribution\n",
        "    attention_distribution = tf.nn.softmax(attention_score, axis=1)\n",
        "\n",
        "    # Weight encoder outputs by attention distribution\n",
        "    weighted_output = attention_distribution * enc_out\n",
        "\n",
        "    # Sum weighted vectors to produce context vector\n",
        "    context_vector = tf.reduce_sum(weighted_output, axis=1)\n",
        "\n",
        "    return context_vector, attention_distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls7v013HipOJ",
        "outputId": "e8afc75d-bb59-4a00-b859-326ee7f7f0f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbBWmhvfu9p4"
      },
      "source": [
        "# **Helper functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpqQl3tPvVLi"
      },
      "outputs": [],
      "source": [
        "START_TOKEN=\"0\"\n",
        "END_TOKEN=\"1\"\n",
        "\n",
        "\n",
        "\"\"\"Retrieve dataset if not already available locally\"\"\"\n",
        "def downloadDataSet():\n",
        "   working_directory = os.getcwd()\n",
        "\n",
        "   dataset_archive_present = exists('./dakshina_dataset_v1.0.tar')\n",
        "   if not dataset_archive_present:\n",
        "     print('initiating download process....')\n",
        "     os.system('wget -q https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar -O dakshina_dataset_v1.0.tar')\n",
        "     print('download operation completed')\n",
        "\n",
        "   dataset_folder_present = exists('./dakshina_dataset_v1.0/')\n",
        "   if not dataset_folder_present:\n",
        "     print('Beginning extraction process..')\n",
        "     try:\n",
        "       dataset_archive = tarfile.open('dakshina_dataset_v1.0.tar', 'r')\n",
        "       dataset_archive.extractall()\n",
        "       dataset_archive.close()\n",
        "     except Exception as e:\n",
        "       print(f\"Extraction error: {e}\")\n",
        "     print('Extraction finished')\n",
        "\n",
        "   print('Dataset preparation complete')\n",
        "\n",
        "\n",
        "def get_files(language):\n",
        "  \"\"\"Construct file paths for the specified language dataset\"\"\"\n",
        "  base_path = f'./dakshina_dataset_v1.0/{language}/lexicons/'\n",
        "  train_dir = f'{base_path}{language}.translit.sampled.train.tsv'\n",
        "  val_dir = f'{base_path}{language}.translit.sampled.dev.tsv'\n",
        "  test_dir = f'{base_path}{language}.translit.sampled.test.tsv'\n",
        "\n",
        "  return train_dir, val_dir, test_dir\n",
        "\n",
        "\n",
        "\"\"\"Convert text data to token sequences\"\"\"\n",
        "def tokenize(lang, tokenizer=None):\n",
        "    \"\"\"Transform text into character-level token sequences\n",
        "\n",
        "    Args:\n",
        "        lang: List of text strings to tokenize\n",
        "        tokenizer: Optional pre-fitted tokenizer\n",
        "\n",
        "    Returns:\n",
        "        Tuple of tokenized sequences and tokenizer object\n",
        "    \"\"\"\n",
        "    if tokenizer is None:\n",
        "        # Initialize new tokenizer if not provided\n",
        "        tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "        # Fit tokenizer on input text data\n",
        "        tokenizer.fit_on_texts(lang)\n",
        "\n",
        "    # Convert text to sequences\n",
        "    lang_sequences = tokenizer.texts_to_sequences(lang)\n",
        "    # Pad sequences to uniform length\n",
        "    lang_tensor = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        lang_sequences,\n",
        "        padding='post'\n",
        "    )\n",
        "\n",
        "    return lang_tensor, tokenizer\n",
        "\n",
        "\n",
        "\"\"\"Prepare dataset for model training\"\"\"\n",
        "def preprocess_data(fpath, ip_tokenizer=None, tgt_tokenizer=None):\n",
        "    \"\"\"Process raw data files into model-ready tensors\n",
        "\n",
        "    Args:\n",
        "        fpath: Path to input data file\n",
        "        ip_tokenizer: Optional input tokenizer\n",
        "        tgt_tokenizer: Optional target tokenizer\n",
        "\n",
        "    Returns:\n",
        "        Tuple of TF dataset, input tokenizer, and target tokenizer\n",
        "    \"\"\"\n",
        "    # Load data from tsv file\n",
        "    data_frame = pd.read_csv(fpath, sep=\"\\t\", header=None)\n",
        "\n",
        "    # Append special tokens to target sequences\n",
        "    data_frame[0] = data_frame[0].apply(lambda x: START_TOKEN + x + END_TOKEN)\n",
        "\n",
        "    # Generate token sequences\n",
        "    input_tensor, ip_tokenizer = tokenize(\n",
        "        data_frame[1].astype(str).tolist(),\n",
        "        tokenizer=ip_tokenizer\n",
        "    )\n",
        "\n",
        "    target_tensor, tgt_tokenizer = tokenize(\n",
        "        data_frame[0].astype(str).tolist(),\n",
        "        tokenizer=tgt_tokenizer\n",
        "    )\n",
        "\n",
        "    # Create and shuffle TensorFlow dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((input_tensor, target_tensor))\n",
        "    dataset = dataset.shuffle(len(dataset))\n",
        "\n",
        "    return dataset, ip_tokenizer, tgt_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOjgMxdSv3jy"
      },
      "outputs": [],
      "source": [
        "# Helper function for creating RNN layers\n",
        "def get_layer(layer_type, units, dropout, return_sequences, return_state):\n",
        "    if layer_type.lower() == \"lstm\":\n",
        "        return tf.keras.layers.LSTM(units,\n",
        "                                    return_sequences=return_sequences,\n",
        "                                    return_state=return_state,\n",
        "                                    dropout=dropout)\n",
        "    elif layer_type.lower() == \"gru\":\n",
        "        return tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=return_sequences,\n",
        "                                   return_state=return_state,\n",
        "                                   dropout=dropout)\n",
        "    elif layer_type.lower() == \"rnn\":\n",
        "        return tf.keras.layers.SimpleRNN(units,\n",
        "                                   return_sequences=return_sequences,\n",
        "                                   return_state=return_state,\n",
        "                                   dropout=dropout)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported layer type: {layer_type}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty-yWidXsJyD"
      },
      "outputs": [],
      "source": [
        "class Parameters():\n",
        "  def  __init__(self,  language='te',encoder_layers=1,decoder_layers=1,embedding_dim=128,\\\n",
        "                layer_type='lstm', units=128, dropout=0.5, attention=False,attention_type=\"Luong\",batch_size=128,\\\n",
        "                apply_beam_search=False,apply_teacher_forcing=False,teacher_forcing_ratio=1,\\\n",
        "                 save_outputs=None,epochs=5,wandb=None,beamWidth=5,restoreBestModel=True,\\\n",
        "                 patience=2,encoder_vocab_size=64,decoder_vocab_size=64):\n",
        "        self.language = language\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.encoder_layers=encoder_layers\n",
        "        self.decoder_layers=decoder_layers\n",
        "        self.layer_type = layer_type\n",
        "        self.units = units\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "        self.stats = []\n",
        "        self.wandb=wandb\n",
        "        self.epochs=epochs\n",
        "        self.batch_size = 128\n",
        "        self.apply_beam_search = apply_beam_search\n",
        "        self.batch_size = batch_size\n",
        "        self.apply_teacher_forcing=apply_teacher_forcing\n",
        "        self.save_outputs=save_outputs\n",
        "        self.restoreBestModel=restoreBestModel\n",
        "        self.attention_type=attention_type\n",
        "        self.patience=patience\n",
        "        self.encoder_vocab_size=encoder_vocab_size\n",
        "        self.decoder_vocab_size=decoder_vocab_size\n",
        "        self.teacher_forcing_ratio=teacher_forcing_ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGRobVz_nX5x"
      },
      "source": [
        "# **Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQSzzTVAsEX0"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, param):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layer_type = param.layer_type.lower()\n",
        "        self.n_layers = param.encoder_layers\n",
        "        self.units = param.units\n",
        "        self.dropout = param.dropout\n",
        "        self.embedding = tf.keras.layers.Embedding(\n",
        "            param.encoder_vocab_size,\n",
        "            param.embedding_dim,\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        # Create RNN layers directly in __init__\n",
        "        self.rnn_layers = []\n",
        "        for i in range(self.n_layers):\n",
        "            # For stacked RNNs, all layers except last should return sequences\n",
        "            return_sequences = True if i < self.n_layers - 1 else True  # Always return sequences for encoder\n",
        "            layer = get_layer(\n",
        "                self.layer_type,\n",
        "                self.units,\n",
        "                self.dropout,\n",
        "                return_sequences=return_sequences,\n",
        "                return_state=True\n",
        "            )\n",
        "            self.rnn_layers.append(layer)\n",
        "\n",
        "        # Add this to ensure the layer is properly built\n",
        "        self.built = True\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, x, hidden=None):\n",
        "        # x: [batch_size, seq_len]\n",
        "        batch_size = tf.shape(x)[0]\n",
        "\n",
        "        # Apply embedding\n",
        "        x = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
        "\n",
        "        # Initialize hidden states if not provided\n",
        "        if hidden is None:\n",
        "            if self.layer_type == \"lstm\":\n",
        "                hidden = []\n",
        "                for _ in range(self.n_layers):\n",
        "                    h = tf.zeros((batch_size, self.units))\n",
        "                    c = tf.zeros((batch_size, self.units))\n",
        "                    hidden.extend([h, c])\n",
        "            else:  # GRU or RNN\n",
        "                hidden = [tf.zeros((batch_size, self.units)) for _ in range(self.n_layers)]\n",
        "\n",
        "        outputs = []\n",
        "        states = []\n",
        "\n",
        "        # Format the hidden states based on RNN type\n",
        "        if self.layer_type == \"lstm\":\n",
        "            hidden_states = []\n",
        "            for i in range(self.n_layers):\n",
        "                if 2*i+1 < len(hidden):\n",
        "                    hidden_states.append([hidden[2*i], hidden[2*i+1]])\n",
        "                else:\n",
        "                    # Default to None if not enough states\n",
        "                    hidden_states.append(None)\n",
        "        else:  # GRU or RNN\n",
        "            hidden_states = []\n",
        "            for i in range(self.n_layers):\n",
        "                if i < len(hidden):\n",
        "                    hidden_states.append(hidden[i])\n",
        "                else:\n",
        "                    hidden_states.append(None)\n",
        "\n",
        "        # Process through RNN layers\n",
        "        current_input = x\n",
        "\n",
        "        for i, rnn in enumerate(self.rnn_layers):\n",
        "            if hidden_states[i] is not None:\n",
        "                if self.layer_type == \"lstm\":\n",
        "                    # For LSTM with initial state\n",
        "                    output, h_state, c_state = rnn(current_input, initial_state=hidden_states[i])\n",
        "                    states.extend([h_state, c_state])\n",
        "                else:\n",
        "                    # For GRU/RNN with initial state\n",
        "                    output, state = rnn(current_input, initial_state=hidden_states[i])\n",
        "                    states.append(state)\n",
        "            else:\n",
        "                # No initial state provided\n",
        "                if self.layer_type == \"lstm\":\n",
        "                    output, h_state, c_state = rnn(current_input)\n",
        "                    states.extend([h_state, c_state])\n",
        "                else:\n",
        "                    output, state = rnn(current_input)\n",
        "                    states.append(state)\n",
        "\n",
        "            current_input = output\n",
        "            outputs.append(output)\n",
        "\n",
        "        # Return the output of last RNN layer and all states\n",
        "        return outputs[-1], states\n",
        "\n",
        "    def initialize_hidden_state(self, batch_size):\n",
        "        if self.layer_type == \"lstm\":\n",
        "            # For LSTM, we need h_state and c_state for each layer\n",
        "            states = []\n",
        "            for _ in range(self.n_layers):\n",
        "                h = tf.zeros((batch_size, self.units))\n",
        "                c = tf.zeros((batch_size, self.units))\n",
        "                states.extend([h, c])\n",
        "        else:\n",
        "            # For GRU/RNN, we need one state per layer\n",
        "            states = [tf.zeros((batch_size, self.units)) for _ in range(self.n_layers)]\n",
        "\n",
        "        return states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBSHDVmgna_A"
      },
      "source": [
        "# **Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQHJ8JtysOCX"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, param):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.layer_type = param.layer_type.lower()\n",
        "        self.n_layers = param.decoder_layers\n",
        "        self.units = param.units\n",
        "        self.dropout = param.dropout\n",
        "        self.attention = param.attention\n",
        "        self.attention_type = getattr(param, 'attention_type', 'bahdanau')\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding_layer = layers.Embedding(\n",
        "            input_dim=param.decoder_vocab_size,\n",
        "            output_dim=param.embedding_dim,\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        # Output dense layer\n",
        "        self.dense = layers.Dense(param.decoder_vocab_size, activation=\"softmax\")\n",
        "\n",
        "        # Attention mechanism\n",
        "        if self.attention:\n",
        "            self.attention_layer = BahdanauAttention(self.units)\n",
        "\n",
        "        # Create RNN layers directly in __init__\n",
        "        self.rnn_layers = []\n",
        "        for i in range(self.n_layers):\n",
        "            return_sequences = True if i < self.n_layers - 1 else False\n",
        "            layer = get_layer(\n",
        "                self.layer_type, self.units, self.dropout,\n",
        "                return_sequences=return_sequences, return_state=True\n",
        "            )\n",
        "            self.rnn_layers.append(layer)\n",
        "\n",
        "        # Add this to ensure the layer is properly built\n",
        "        self.built = True\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, x, hidden, enc_out=None):\n",
        "        # x: [batch_size, 1]\n",
        "        # hidden: list of states from encoder\n",
        "        # enc_out: encoder outputs for attention\n",
        "\n",
        "        # Apply embedding\n",
        "        x = self.embedding_layer(x)  # [batch_size, 1, embedding_dim]\n",
        "\n",
        "        attention_weights = None\n",
        "\n",
        "        # Format hidden states based on RNN type\n",
        "        if self.layer_type == \"lstm\":\n",
        "            # For LSTM, we need h_state and c_state for each layer\n",
        "            hidden_states = []\n",
        "            for i in range(self.n_layers):\n",
        "                if 2*i+1 < len(hidden):\n",
        "                    hidden_states.append([hidden[2*i], hidden[2*i+1]])\n",
        "                else:\n",
        "                    hidden_states.append(None)\n",
        "\n",
        "            # Use first hidden state for attention\n",
        "            attention_state = hidden[0] if hidden else None\n",
        "        else:\n",
        "            # For GRU/RNN, we need one state per layer\n",
        "            hidden_states = []\n",
        "            for i in range(self.n_layers):\n",
        "                if i < len(hidden):\n",
        "                    hidden_states.append(hidden[i])\n",
        "                else:\n",
        "                    hidden_states.append(None)\n",
        "\n",
        "            # Use first hidden state for attention\n",
        "            attention_state = hidden[0] if hidden else None\n",
        "\n",
        "        # Apply attention if enabled\n",
        "        if self.attention and enc_out is not None and attention_state is not None:\n",
        "            # Apply attention mechanism\n",
        "            context_vector, attention_weights = self.attention_layer(attention_state, enc_out)\n",
        "\n",
        "            # Expand context vector to match x's time dimension\n",
        "            context_vector_expanded = tf.expand_dims(context_vector, 1)\n",
        "\n",
        "            # Concatenate context vector with input embedding along feature dimension\n",
        "            x = tf.concat([context_vector_expanded, x], axis=-1)\n",
        "\n",
        "        # Process through RNN layers\n",
        "        states = []\n",
        "        current_input = x\n",
        "\n",
        "        for i, rnn in enumerate(self.rnn_layers):\n",
        "            if hidden_states[i] is not None:\n",
        "                if self.layer_type == \"lstm\":\n",
        "                    # For LSTM with initial state\n",
        "                    output, h_state, c_state = rnn(current_input, initial_state=hidden_states[i])\n",
        "                    states.extend([h_state, c_state])\n",
        "                else:\n",
        "                    # For GRU/RNN with initial state\n",
        "                    output, state = rnn(current_input, initial_state=hidden_states[i])\n",
        "                    states.append(state)\n",
        "            else:\n",
        "                # No initial state provided\n",
        "                if self.layer_type == \"lstm\":\n",
        "                    output, h_state, c_state = rnn(current_input)\n",
        "                    states.extend([h_state, c_state])\n",
        "                else:\n",
        "                    output, state = rnn(current_input)\n",
        "                    states.append(state)\n",
        "\n",
        "            current_input = output\n",
        "\n",
        "        # Apply the dense layer to get output probabilities\n",
        "        # If the last RNN layer returns sequences, take only the last timestep\n",
        "        if len(output.shape) > 2:\n",
        "            output = output[:, -1, :]\n",
        "\n",
        "        # Get final output prediction\n",
        "        prediction = self.dense(output)\n",
        "\n",
        "        return prediction, states, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlqAZqpankTQ"
      },
      "source": [
        "# **SequenceTOSequence**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa0XPzaFsSkW"
      },
      "outputs": [],
      "source": [
        "\n",
        "class SequenceTOSequence():\n",
        "    def __init__(self, parameters):\n",
        "        #Basic configurations\n",
        "        self.param = parameters\n",
        "        self.embedding_dim = parameters.embedding_dim\n",
        "        self.encoder_layers = parameters.encoder_layers\n",
        "        self.decoder_layers = parameters.decoder_layers\n",
        "        self.layer_type = parameters.layer_type\n",
        "        self.units = parameters.units\n",
        "        self.dropout = parameters.dropout\n",
        "        self.batch_size = parameters.batch_size\n",
        "\n",
        "        #Add information regarding attention layer\n",
        "        self.attention = parameters.attention\n",
        "        self.attention_type = parameters.attention_type\n",
        "\n",
        "        self.stats = []\n",
        "\n",
        "        self.apply_beam_search = parameters.apply_beam_search\n",
        "\n",
        "        #Early stop conditions\n",
        "        self.patience = parameters.patience\n",
        "        self.restoreBestModel = parameters.restoreBestModel\n",
        "\n",
        "        #teacher forcing\n",
        "        self.apply_teacher_forcing = parameters.apply_teacher_forcing\n",
        "        self.teacher_forcing_ratio = parameters.teacher_forcing_ratio\n",
        "\n",
        "    #Build model Add specific optimizers\n",
        "    def build(self, loss, metric, optimizer='adam', lr=0.001):\n",
        "        self.loss = loss\n",
        "\n",
        "        #Select specific optimizer\n",
        "        if(optimizer=='adam'):\n",
        "            self.optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "        if(optimizer=='nadam'):\n",
        "            self.optimizer = tf.keras.optimizers.Nadam(learning_rate=lr)\n",
        "        else:\n",
        "            self.optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
        "\n",
        "        self.metric = metric\n",
        "\n",
        "    def set_vocabulary(self, input_tokenizer, targ_tokenizer):\n",
        "        self.input_tokenizer = input_tokenizer\n",
        "        self.targ_tokenizer = targ_tokenizer\n",
        "        self.create_model()\n",
        "\n",
        "    \"\"\"This procedure used to define Encoder Decoder Layer\"\"\"\n",
        "    def create_model(self):\n",
        "        encoder_vocab_size = len(self.input_tokenizer.word_index) + 1\n",
        "        decoder_vocab_size = len(self.targ_tokenizer.word_index) + 1\n",
        "        self.param.encoder_vocab_size = encoder_vocab_size\n",
        "        self.param.decoder_vocab_size = decoder_vocab_size\n",
        "\n",
        "        #Add Encoder layer\n",
        "        self.encoder = Encoder(self.param)\n",
        "\n",
        "        #Create decode with or without any attention layer\n",
        "        #Check following properties to add attention\n",
        "        # self.attention\n",
        "        # self.attention_type\n",
        "        self.decoder = Decoder(self.param)\n",
        "\n",
        "    @tf.function\n",
        "    def train(self, input, target, enc_state):\n",
        "        \"\"\"\n",
        "        Training step function with gradient tape.\n",
        "        Handles both teacher forcing and non-teacher forcing modes.\n",
        "\n",
        "        Args:\n",
        "            input: Input tensor of shape [batch_size, max_input_len]\n",
        "            target: Target tensor of shape [batch_size, max_target_len]\n",
        "            enc_state: Initial encoder state\n",
        "\n",
        "        Returns:\n",
        "            batch_loss: Average loss for this batch\n",
        "            accuracy: Current accuracy metric value\n",
        "        \"\"\"\n",
        "        loss = 0\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Run input through encoder\n",
        "            enc_out, enc_state = self.encoder(input, enc_state)\n",
        "\n",
        "            # Set initial state of decoder from encoder state\n",
        "            dec_state = enc_state\n",
        "\n",
        "            # Start token for all sequences in the batch\n",
        "            dec_input = tf.expand_dims([self.targ_tokenizer.word_index[\"\\t\"]] * self.batch_size, 1)\n",
        "\n",
        "            # Determine whether to use teacher forcing for this batch\n",
        "            apply_teacher_forcing = False\n",
        "            if self.apply_teacher_forcing and random.random() < self.teacher_forcing_ratio:\n",
        "                apply_teacher_forcing = True\n",
        "\n",
        "            # Teacher forcing: use actual target tokens as next input\n",
        "            if apply_teacher_forcing:\n",
        "                for t in range(1, target.shape[1]):\n",
        "                    # Pass the decoder input, state, and encoder output to the decoder\n",
        "                    preds, dec_state, _ = self.decoder(dec_input, dec_state, enc_out)\n",
        "\n",
        "                    # Calculate loss and update metrics\n",
        "                    loss += self.loss(target[:, t], preds)\n",
        "                    self.metric.update_state(target[:, t], preds)\n",
        "\n",
        "                    # Use the actual target as the next decoder input (teacher forcing)\n",
        "                    dec_input = tf.expand_dims(target[:, t], 1)\n",
        "\n",
        "            # No teacher forcing: use model's own predictions as next input\n",
        "            else:\n",
        "                for t in range(1, target.shape[1]):\n",
        "                    # Pass the decoder input, state, and encoder output to the decoder\n",
        "                    preds, dec_state, _ = self.decoder(dec_input, dec_state, enc_out)\n",
        "\n",
        "                    # Calculate loss and update metrics\n",
        "                    loss += self.loss(target[:, t], preds)\n",
        "                    self.metric.update_state(target[:, t], preds)\n",
        "\n",
        "                    # Use our own prediction as the next decoder input\n",
        "                    predicted_ids = tf.argmax(preds, axis=1)\n",
        "                    dec_input = tf.expand_dims(predicted_ids, 1)\n",
        "\n",
        "            # Calculate average loss per time step\n",
        "            batch_loss = loss / tf.cast(target.shape[1], dtype=tf.float32)\n",
        "\n",
        "            # Get all trainable variables and apply gradients\n",
        "            variables = self.encoder.trainable_variables + self.decoder.trainable_variables\n",
        "            gradients = tape.gradient(loss, variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "        return batch_loss, self.metric.result()\n",
        "\n",
        "    def fit(self, dataset, val_dataset, batch_size=128, epochs=5, wandb=None, apply_teacher_forcing=True, teacher_forcing_ratio=0.7):\n",
        "        self.batch_size = batch_size\n",
        "        self.apply_teacher_forcing = apply_teacher_forcing\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        #Prepare chunk of data based on batch size provided\n",
        "        steps_per_epoch = len(dataset) // self.batch_size\n",
        "        #steps_per_epoch_val = len(val_dataset) // self.batch_size\n",
        "\n",
        "        dataset = dataset.batch(self.batch_size, drop_remainder=False)\n",
        "        #val_dataset = val_dataset.batch(self.batch_size, drop_remainder=False)\n",
        "\n",
        "        sample_inp, sample_targ = next(iter(dataset))\n",
        "        self.max_target_len = sample_targ.shape[1]\n",
        "        self.max_input_len = sample_inp.shape[1]\n",
        "\n",
        "        #Store Encoder, decoder details in case model get good accuracy\n",
        "        #Will be useful to restore best model\n",
        "        self.bestEncoder = self.encoder\n",
        "        self.bestDecoder = self.decoder\n",
        "        self.bestoptimizer = self.optimizer\n",
        "\n",
        "        accuracyDegradePatience = 0\n",
        "        self.oldaccuracy = 0\n",
        "        for epoch in tqdm(range(1, epochs+1), total=epochs, desc=\"Epochs \"):\n",
        "            if(accuracyDegradePatience >= self.patience):\n",
        "                if(self.restoreBestModel == True):\n",
        "                    self.encoder = self.bestEncoder\n",
        "                    self.decoder = self.bestDecoder\n",
        "                    self.optimizer = self.bestoptimizer\n",
        "                break\n",
        "\n",
        "            ## Training loop ##\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "            self.metric.reset_state()\n",
        "\n",
        "            starting_time = time.time()\n",
        "            enc_state = self.encoder.initialize_hidden_state(self.batch_size)\n",
        "\n",
        "            for batch, (input, target) in enumerate(dataset.take(steps_per_epoch)):\n",
        "                #Accumulate loss and accuracy for each batch\n",
        "                batch_loss, acc = self.train(input, target, enc_state)\n",
        "                total_loss += batch_loss\n",
        "                total_acc += acc\n",
        "\n",
        "            #Calculate validation accuracy for current Epoch\n",
        "            avg_acc = total_acc / steps_per_epoch\n",
        "            avg_loss = total_loss / steps_per_epoch\n",
        "\n",
        "            # Validation loop ##\n",
        "            total_val_loss = 0\n",
        "            total_val_acc = 0\n",
        "            self.metric.reset_state()\n",
        "\n",
        "            enc_state = self.encoder.initialize_hidden_state(self.batch_size)\n",
        "\n",
        "            #Process data in batches\n",
        "            avg_val_loss, avg_val_acc = self.evaluate(val_dataset, batch_size=self.batch_size)\n",
        "\n",
        "            #Verify if model performance degrading\n",
        "            #In case train accuracy improved but no significant improvement in validation\n",
        "            #Add condition for early stopping\n",
        "            #Restore best model based on the input\n",
        "            if(self.oldaccuracy > avg_val_acc):\n",
        "                accuracyDegradePatience += 1\n",
        "            else:\n",
        "                self.bestEncoder = self.encoder\n",
        "                self.bestDecoder = self.decoder\n",
        "                self.bestoptimizer = self.optimizer\n",
        "                self.oldaccuracy = avg_val_acc\n",
        "                accuracyDegradePatience = 0\n",
        "\n",
        "            print(\"\\nTrain Loss: {0:.4f} Train Accuracy: {1:.4f} Validation Loss: {2:.4f} Validation Accuracy: {3:.4f}\".format(\n",
        "                avg_loss, avg_acc*100, avg_val_loss, avg_val_acc*100))\n",
        "\n",
        "            time_taken = time.time() - starting_time\n",
        "\n",
        "            #Add logs for WanDb\n",
        "            self.stats.append({\n",
        "                \"epoch\": epoch,\n",
        "                \"train_loss\": avg_loss,\n",
        "                \"val_loss\": avg_val_loss,\n",
        "                \"train_acc\": avg_acc*100,\n",
        "                \"val_acc\": avg_val_acc*100,\n",
        "                \"training time\": time_taken\n",
        "            })\n",
        "\n",
        "            #Log to wanDB\n",
        "            if not (wandb is None):\n",
        "                wandb.log(self.stats[-1])\n",
        "\n",
        "            print(f\"\\nTime taken for the epoch {time_taken:.4f}\")\n",
        "\n",
        "        print(\"\\nModel trained successfully !!\")\n",
        "\n",
        "    @tf.function\n",
        "    def validation(self, inp, trgt, encoder_state):\n",
        "        \"\"\"\n",
        "        Validation step function.\n",
        "        Always uses the model's predictions as the next input (no teacher forcing).\n",
        "\n",
        "        Args:\n",
        "            inp: Input tensor of shape [batch_size, max_input_len]\n",
        "            trgt: Target tensor of shape [batch_size, max_target_len]\n",
        "            encoder_state: Initial encoder state\n",
        "\n",
        "        Returns:\n",
        "            batch_loss: Average loss for this batch\n",
        "            accuracy: Current accuracy metric value\n",
        "        \"\"\"\n",
        "        loss = 0\n",
        "\n",
        "        # Run input through encoder\n",
        "        encoder_output, encoder_state = self.encoder(inp, encoder_state)\n",
        "\n",
        "        # Set initial state of decoder from encoder state\n",
        "        decoder_state = encoder_state\n",
        "\n",
        "        # Start token for all sequences in the batch\n",
        "        decoder_input = tf.expand_dims([self.targ_tokenizer.word_index[\"\\t\"]] * self.batch_size, 1)\n",
        "\n",
        "        # Process each time step\n",
        "        for t in range(1, trgt.shape[1]):\n",
        "            # Get decoder prediction\n",
        "            prediction, decoder_state, _ = self.decoder(decoder_input, decoder_state, encoder_output)\n",
        "\n",
        "            # Calculate loss and update metrics\n",
        "            loss += self.loss(trgt[:, t], prediction)\n",
        "            self.metric.update_state(trgt[:, t], prediction)\n",
        "\n",
        "            # Use our own prediction as the next decoder input\n",
        "            predicted_ids = tf.argmax(prediction, axis=1)\n",
        "            decoder_input = tf.expand_dims(predicted_ids, 1)\n",
        "\n",
        "        # Calculate average loss per time step\n",
        "        batch_loss = loss / tf.cast(trgt.shape[1], dtype=tf.float32)\n",
        "\n",
        "        return batch_loss, self.metric.result()\n",
        "\n",
        "    def evaluate(self, test_dataset, batch_size=None):\n",
        "        \"\"\"Evaluate our model on test data\"\"\"\n",
        "        if batch_size is not None:\n",
        "            self.batch_size = batch_size\n",
        "\n",
        "        #prepare chunk of data based on the batch size\n",
        "        steps_per_epoch_test = len(test_dataset) // batch_size\n",
        "        test_dataset = test_dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "        total_test_loss = 0\n",
        "        total_test_acc = 0\n",
        "        self.metric.reset_state()\n",
        "\n",
        "        enc_state = self.encoder.initialize_hidden_state(self.batch_size)\n",
        "\n",
        "        #print(\"\\nRunning test dataset through the model...\\n\")\n",
        "        #Run in batches based on the input batch size\n",
        "        for batch, (input, target) in enumerate(test_dataset.take(steps_per_epoch_test)):\n",
        "            batch_loss, acc = self.validation(input, target, enc_state)\n",
        "            total_test_loss += batch_loss\n",
        "            total_test_acc += acc\n",
        "\n",
        "        #Calculate average test accuracy and loss\n",
        "        avg_test_acc = total_test_acc / steps_per_epoch_test\n",
        "        avg_test_loss = total_test_loss / steps_per_epoch_test\n",
        "\n",
        "        #Display details\n",
        "        #print(f\"Test Loss: {avg_test_loss:.4f} Test Accuracy: {avg_test_acc:.4f}\")\n",
        "\n",
        "        return avg_test_loss, avg_test_acc\n",
        "\n",
        "    \"\"\" This function used to translate english word to respective language\"\"\"\n",
        "    def translate(self, word, get_heatmap=False):\n",
        "        \"\"\"\n",
        "        Translate an input word to the target language.\n",
        "\n",
        "        Args:\n",
        "            word: Input word or sentence to translate\n",
        "            get_heatmap: Whether to return attention weights for visualization\n",
        "\n",
        "        Returns:\n",
        "            result: Translated text\n",
        "            att_wts: Attention weights (if get_heatmap=True)\n",
        "        \"\"\"\n",
        "        # Add start and end tokens for input word\n",
        "        start = \"\\t\"\n",
        "        end = \"\\n\"\n",
        "        word = start + word + end\n",
        "\n",
        "        # Tokenize and pad input\n",
        "        inputs = self.input_tokenizer.texts_to_sequences([word])\n",
        "        inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "            inputs,\n",
        "            maxlen=self.max_input_len,\n",
        "            padding=\"post\"\n",
        "        )\n",
        "\n",
        "        # Initialize result string and attention weights list\n",
        "        result = \"\"\n",
        "        att_wts = []\n",
        "\n",
        "        # Initialize encoder state and run input through encoder\n",
        "        enc_state = self.encoder.initialize_hidden_state(1)\n",
        "        enc_out, enc_state = self.encoder(inputs, enc_state)\n",
        "\n",
        "        # Set initial decoder state to encoder state\n",
        "        dec_state = enc_state\n",
        "\n",
        "        # Start token as first decoder input\n",
        "        dec_input = tf.expand_dims([self.targ_tokenizer.word_index[start]], 1)\n",
        "\n",
        "        # Generate translation one token at a time\n",
        "        for t in range(1, self.max_target_len):\n",
        "            # Get prediction from decoder\n",
        "            preds, dec_state, attention_weights = self.decoder(dec_input, dec_state, enc_out)\n",
        "\n",
        "            # Store attention weights if needed\n",
        "            if get_heatmap and attention_weights is not None:\n",
        "                att_wts.append(attention_weights)\n",
        "\n",
        "            # Get the predicted token ID\n",
        "            predicted_id = tf.argmax(preds, axis=1)\n",
        "\n",
        "            # Convert ID to character/word\n",
        "            next_char = self.targ_tokenizer.index_word.get(predicted_id.numpy().item(), \"<UNK>\")\n",
        "\n",
        "            # Add to result\n",
        "            result += next_char\n",
        "\n",
        "            # Use prediction as next input\n",
        "            dec_input = tf.expand_dims(predicted_id, 1)\n",
        "\n",
        "            # Stop if end token is generated\n",
        "            if next_char == end:\n",
        "                break\n",
        "\n",
        "        # Remove the end token if present\n",
        "        if result.endswith(end):\n",
        "            result = result[:-1]\n",
        "\n",
        "        return result, att_wts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC_ETEF9rIxM"
      },
      "source": [
        "# **wandb**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dS2JhY05vMR"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "hLEZUp3W5wf9",
        "outputId": "3a8f0350-d345-4c25-b14a-eee55c4baf28"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mna21b050\u001b[0m (\u001b[33mna21b050-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250520_125935-hb87mo5d</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/na21b050-iit-madras/uncategorized/runs/hb87mo5d' target=\"_blank\">glorious-field-11</a></strong> to <a href='https://wandb.ai/na21b050-iit-madras/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/na21b050-iit-madras/uncategorized' target=\"_blank\">https://wandb.ai/na21b050-iit-madras/uncategorized</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/na21b050-iit-madras/uncategorized/runs/hb87mo5d' target=\"_blank\">https://wandb.ai/na21b050-iit-madras/uncategorized/runs/hb87mo5d</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/na21b050-iit-madras/uncategorized/runs/hb87mo5d?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x791a2b10f510>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCVhhqPMWkuS"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5Bt3Bf-_JhQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "START_TOKEN=\"\\t\"\n",
        "END_TOKEN=\"\\n\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWI9X48FjCPy",
        "outputId": "758a7afe-2b0c-44c2-99eb-f5a8cff79cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initiating download process....\n",
            "download operation completed\n",
            "Beginning extraction process..\n",
            "Extraction finished\n",
            "Dataset preparation complete\n"
          ]
        }
      ],
      "source": [
        "downloadDataSet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ji0OxT0yxRA"
      },
      "outputs": [],
      "source": [
        "language=\"te\"\n",
        "train_dir, val_dir, test_dir = get_files(language)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWOhUaVWipOU"
      },
      "outputs": [],
      "source": [
        "dataset, input_tokenizer, targ_tokenizer = preprocess_data(train_dir)\n",
        "val_dataset, _, _ = preprocess_data(val_dir,input_tokenizer,targ_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A57aPT6P6uyg"
      },
      "outputs": [],
      "source": [
        "#train data\n",
        "dataset, input_tokenizer, targ_tokenizer = preprocess_data(train_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlbXxZXZjpEq"
      },
      "source": [
        "## Sweep Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikX_8MejzT7-"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "  \"name\": \"DL_Assignment3_Rnn\",\n",
        "  \"method\": \"bayes\",\n",
        "  \"metric\": {\n",
        "      \"name\": \"val_acc\",\n",
        "      \"goal\": \"maximize\",\n",
        "  },\n",
        "\n",
        "  \"parameters\": {\n",
        "        \"num_of_encoders\":{\n",
        "          \"values\":[1,2,3]\n",
        "        },\n",
        "        \"num_of_decoders\":{\n",
        "            \"values\":[1,2,3]\n",
        "\n",
        "        },\n",
        "        \"cell_type\":{\n",
        "          \"values\":['gru', 'lstm']\n",
        "        },\n",
        "\n",
        "\n",
        "        \"lr\":{\n",
        "          \"values\":[0.001,0.005]\n",
        "        },\n",
        "        \"optimizer\":{\n",
        "          \"values\":['adam','rmsprop']\n",
        "        },\n",
        "        \"dropout\":{ \"values\": [0.3,0.5]},\n",
        "        \"latent_dim\":{ \"values\": [128,256,512]},\n",
        "        \"inp_emb_size\": {\"values\": [64,128,256]},\n",
        "\n",
        "        \"batch_size\":{\"values\":[32,64,128]},\n",
        "\n",
        "        }\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLqvdjRdweWb"
      },
      "source": [
        "# wandb runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dt9LTQAzZHh"
      },
      "outputs": [],
      "source": [
        "# This is the main function to use to train/fine-tune the model using wandb runs\n",
        "def train_wandb():\n",
        "    run = wandb.init()\n",
        "\n",
        "    config=wandb.config\n",
        "    # Set the run name\n",
        "    name=\"num_of_encoders(\"+ str(config[\"num_of_encoders\"]) + \")_\"\n",
        "    name = \" num_of_decoders(\" + str(config[\"num_of_decoders\"]) + \")_\"\n",
        "    name += \" cell_type(\" + str(config[\"cell_type\"]) + \")_\"\n",
        "\n",
        "    name += \"latent_dim(\" + str(config[\"latent_dim\"])+ \")_\"\n",
        "    name += \"lr(\" + str(config[\"lr\"])+ \")_\"\n",
        "    name += \"optimizer(\" + str(config[\"optimizer\"]) + \")_\"\n",
        "    name += \"dropout(\" + str(config[\"dropout\"]) + \")\"\n",
        "    name += \"inp_emb_size(\" + str(config[\"inp_emb_size\"]) + \")_\"\n",
        "    name+=\"batch_size(\" + str(config[\"batch_size\"]) + \")\"\n",
        "\n",
        "\n",
        "    wandb.run.name = name[:-1]\n",
        "    batch_size=config[\"batch_size\"]\n",
        "    inp_emb_size=config[\"inp_emb_size\"]\n",
        "    dropout=config[\"dropout\"]\n",
        "    optimizer=config[\"optimizer\"]\n",
        "    num_of_encoders=config[\"num_of_encoders\"]\n",
        "    num_of_decoders=config[\"num_of_decoders\"]\n",
        "\n",
        "    lr=config[\"lr\"]\n",
        "    latent_dim=config[\"latent_dim\"]\n",
        "    cell_type=config[\"cell_type\"]\n",
        "\n",
        "\n",
        "    param=Parameters(language=\"te\",\\\n",
        "                        embedding_dim=inp_emb_size,\\\n",
        "                        encoder_layers=num_of_encoders,\\\n",
        "                        decoder_layers=num_of_decoders,\\\n",
        "                        layer_type=cell_type,\\\n",
        "                        units=latent_dim,\\\n",
        "                        dropout=dropout,\n",
        "                        epochs=15,\\\n",
        "                 batch_size=batch_size\\\n",
        "                   )\n",
        "    param.apply_teacher_forcing=True\n",
        "    param.teacher_forcing_ratio=1\n",
        "    param.patience=5\n",
        "    param.attention=True\n",
        "    model = SequenceTOSequence(param)\n",
        "    model.set_vocabulary(input_tokenizer, targ_tokenizer)\n",
        "\n",
        "    model.build(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\\\n",
        "                metric = tf.keras.metrics.SparseCategoricalAccuracy(),\\\n",
        "                optimizer = optimizer,\\\n",
        "                lr=lr\\\n",
        "                )\n",
        "\n",
        "    model.fit(dataset, val_dataset, epochs=param.epochs, wandb=wandb,teacher_forcing_ratio=param.teacher_forcing_ratio)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzkdsWRlZzTf",
        "outputId": "0fceb909-58b6-47c4-e0bd-961c26d86b3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 3chor4a8\n",
            "Sweep URL: https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3/sweeps/3chor4a8\n"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, entity=\"na21b050-iit-madras\", project=\"DA6401_Assignment3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LGxzAfZ42R_u",
        "outputId": "6431853c-717a-4dec-ff12-75d556ca88a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 36oy2opv with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinp_emb_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_of_decoders: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_of_encoders: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250520_130016-36oy2opv</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3/runs/36oy2opv' target=\"_blank\">playful-sweep-1</a></strong> to <a href='https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3/sweeps/3chor4a8' target=\"_blank\">https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3/sweeps/3chor4a8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3' target=\"_blank\">https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3/sweeps/3chor4a8' target=\"_blank\">https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3/sweeps/3chor4a8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3/runs/36oy2opv' target=\"_blank\">https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3/runs/36oy2opv</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs :   7%|         | 1/15 [06:20<1:28:40, 380.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.5745 Train Accuracy: 74.4717 Validation Loss: 1.4500 Validation Accuracy: 79.2393\n",
            "\n",
            "Time taken for the epoch 380.0484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs :  13%|        | 2/15 [12:01<1:17:21, 357.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.2127 Train Accuracy: 92.4727 Validation Loss: 1.2167 Validation Accuracy: 83.5534\n",
            "\n",
            "Time taken for the epoch 340.9487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs :  20%|        | 3/15 [17:43<1:10:05, 350.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.1576 Train Accuracy: 94.7616 Validation Loss: 1.1114 Validation Accuracy: 85.8020\n",
            "\n",
            "Time taken for the epoch 342.6463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs :  27%|       | 4/15 [23:25<1:03:36, 346.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.1325 Train Accuracy: 95.7174 Validation Loss: 1.0958 Validation Accuracy: 86.3245\n",
            "\n",
            "Time taken for the epoch 341.6053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs :  33%|      | 5/15 [29:08<57:36, 345.68s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.1181 Train Accuracy: 96.1778 Validation Loss: 1.1814 Validation Accuracy: 85.7141\n",
            "\n",
            "Time taken for the epoch 343.3825\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs :  40%|      | 6/15 [34:51<51:42, 344.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.1086 Train Accuracy: 96.5209 Validation Loss: 1.0986 Validation Accuracy: 86.5572\n",
            "\n",
            "Time taken for the epoch 342.7117\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs :  47%|     | 7/15 [40:51<46:37, 349.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.1012 Train Accuracy: 96.7200 Validation Loss: 1.1918 Validation Accuracy: 86.1602\n",
            "\n",
            "Time taken for the epoch 360.1393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs :  53%|    | 8/15 [46:36<40:37, 348.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0965 Train Accuracy: 96.9018 Validation Loss: 1.1490 Validation Accuracy: 86.3646\n",
            "\n",
            "Time taken for the epoch 344.8134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs :  60%|    | 9/15 [52:26<34:52, 348.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0926 Train Accuracy: 97.0241 Validation Loss: 1.1729 Validation Accuracy: 86.5146\n",
            "\n",
            "Time taken for the epoch 349.8802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs :  67%|   | 10/15 [58:10<28:57, 347.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0894 Train Accuracy: 97.1600 Validation Loss: 1.1357 Validation Accuracy: 87.0026\n",
            "\n",
            "Time taken for the epoch 344.5122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs :  73%|  | 11/15 [1:03:57<23:09, 347.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0863 Train Accuracy: 97.2949 Validation Loss: 1.1673 Validation Accuracy: 86.5767\n",
            "\n",
            "Time taken for the epoch 347.1559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs :  80%|  | 12/15 [1:09:45<17:22, 347.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0849 Train Accuracy: 97.2945 Validation Loss: 1.1729 Validation Accuracy: 86.4583\n",
            "\n",
            "Time taken for the epoch 347.3628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs :  87%| | 13/15 [1:15:31<11:33, 346.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0826 Train Accuracy: 97.3613 Validation Loss: 1.1812 Validation Accuracy: 86.7623\n",
            "\n",
            "Time taken for the epoch 346.0187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs :  93%|| 14/15 [1:21:14<05:45, 345.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0813 Train Accuracy: 97.3838 Validation Loss: 1.2079 Validation Accuracy: 86.1286\n",
            "\n",
            "Time taken for the epoch 342.9758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs : 100%|| 15/15 [1:27:01<00:00, 348.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0800 Train Accuracy: 97.4645 Validation Loss: 1.1942 Validation Accuracy: 86.5053\n",
            "\n",
            "Time taken for the epoch 347.4260\n",
            "\n",
            "Model trained successfully !!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>training time</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>97.46445</td></tr><tr><td>train_loss</td><td>0.07996</td></tr><tr><td>training time</td><td>347.42601</td></tr><tr><td>val_acc</td><td>86.50532</td></tr><tr><td>val_loss</td><td>1.19424</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\"> num_of_decoders(1)_ cell_type(gru)_latent_dim(128)_lr(0.005)_optimizer(rmsprop)_dropout(0.5)inp_emb_size(256)_batch_size(128</strong> at: <a href='https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3/runs/36oy2opv' target=\"_blank\">https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3/runs/36oy2opv</a><br> View project at: <a href='https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3' target=\"_blank\">https://wandb.ai/na21b050-iit-madras/DA6401_Assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250520_130016-36oy2opv/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x791a2d133b50>> (for post_run_cell):\n"
          ]
        },
        {
          "ename": "BrokenPipeError",
          "evalue": "[Errno 32] Broken pipe",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_post_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmailbox_slot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerResponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        }
      ],
      "source": [
        "wandb.agent(sweep_id, train_wandb, count = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPwW8JoHx8As"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}